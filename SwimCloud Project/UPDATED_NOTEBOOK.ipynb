{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conference-Based Sampling Plan (10 Conferences)\n",
    "\n",
    "The goal is to create a representative sample of swim times across all collegiate divisions. Instead of sampling the top swimmers, which would miss the full spectrum of athlete performance, this plan samples **entire conferences**. This method captures both elite and developmental swimmers, providing a more accurate picture of the population.\n",
    "\n",
    "We merge **NAIA with Division III** for the following reasons:\n",
    "- Their performance levels are statistically similar.\n",
    "- Several NAIA schools already share conferences with DIII programs.\n",
    "\n",
    "### Allocation (10 conferences total)\n",
    "- D1 Power (50 schools): 1 conference\n",
    "- D1 Mid-Major (94 schools): 2 conferences\n",
    "- D2 (75 schools): 2 conferences\n",
    "- D3 + NAIA (232 + 35 = 267 schools): 5 conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, json\n",
    "random.seed(42)  # fixed seed for reproducibility\n",
    "\n",
    "# Confirmed conference lists from PDF (abridged)\n",
    "conferences = {\n",
    "    'D1_Power': [\n",
    "        'Atlantic Coast (ACC)', 'Big Ten', 'Big 12', 'Pac-12', 'Southeastern (SEC)'\n",
    "    ],\n",
    "    'D1_MidMajor': [\n",
    "        'Atlantic 10', 'ASUN', 'Big East', 'Big West',\n",
    "        'Coastal Athletic Association (CAA)', 'Conference USA', 'Horizon League', 'Ivy League',\n",
    "        'Metro Atlantic (MAAC)', 'Mid-American (MAC)', 'Missouri Valley (MVC)', 'Mountain West',\n",
    "        'Northeast (NEC)', 'Ohio Valley', 'Patriot League', 'Summit League', 'Sun Belt', 'WAC'\n",
    "    ],\n",
    "    'D2': [\n",
    "        'CCAA', 'Conference Carolinas', 'East Coast (ECC)', 'GLVC', 'G-MAC', 'GSC',\n",
    "        'Lone Star', 'MIAA', 'NE-10', 'NSIC', 'PacWest', 'Peach Belt', 'PSAC',\n",
    "        'RMAC', 'South Atlantic', 'SIAC', 'Sunshine State'\n",
    "    ],\n",
    "    'D3_NAIA': [\n",
    "        'Allegheny Mountain (AMCC)', 'American Rivers (ARC)', 'Centennial', 'CCIW', 'Empire 8',\n",
    "        'GNAC', 'HCAC', 'Landmark', 'Liberal Arts', 'Liberty League', 'Little East (LEC)', 'MAC', 'MASCAC',\n",
    "        'MIAA', 'MIAC', 'NCAC', 'NESCAC', 'NEWMAC', 'NJAC', 'NACC', 'OAC', 'ODAC', 'PAC',\n",
    "        'SAA', 'SCIAC', 'SCAC', 'SLIAC', 'SUNYAC', 'UAA', 'UMAC', 'USA South', 'WIAC',\n",
    "        'Appalachian Athletic (NAIA)', 'Cascade Collegiate (NAIA)',\n",
    "          'KCAC (NAIA)', 'Mid-South (NAIA)',\n",
    "         'The Sun (NAIA)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Target allocation for 10 conferences\n",
    "sample_sizes = {\n",
    "    'D1_Power': 1,\n",
    "    'D1_MidMajor': 2,\n",
    "    'D2': 2,\n",
    "    'D3_NAIA': 5\n",
    "}\n",
    "\n",
    "sampled = {}\n",
    "for div, k in sample_sizes.items():\n",
    "    sampled[div] = random.sample(conferences[div], k)\n",
    "\n",
    "print(json.dumps(sampled, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justification for Combining NAIA and Division III\n",
    "\n",
    "The NAIA and Division III exhibit similar performance distributions, with the primary difference being the smaller population of NAIA teams (approximately a 7:1 ratio to Division III teams). A Kolmogorov-Smirnov (K-S) test was performed to statistically validate this observation.\n",
    "\n",
    "The K-S test shows **no statistically significant difference** between NAIA and Division III score distributions (D = 0.1429 < critical value of 0.2791, p = 0.089). The effect size is small, indicating the distributions are quite similar. Combining these datasets will **not significantly skew the analysis**, as the distributions are statistically equivalent for practical purposes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Data from ks_test_summary.md\n",
    "naia_scores = [769.35, 703.5, 699, 697.5, 692.45, 670.1, 657.5, 655.25, 654.25, 652.65, 637.9, 637.55, 612.45, 612.1, 609.15, 598.7, 589.45, 581.6, 573.45, 564.5, 563.75, 557.6, 554.55, 552.3, 546.73, 537.75, 515.8, 492.1, 477.05, 471.28, 325.4, 316.11, 302.38, 222.85, 188.44]\n",
    "diii_scores = [758.95, 744.3, 741.5, 741.3, 737.3, 730.9, 730.4, 730.25, 722.9, 717, 713.2, 710.3, 704.45, 699.7, 698.35, 697.95, 695.45, 694.6, 693.95, 691.3, 687.65, 685.25, 681, 679.45, 678.05, 676.8, 675.2, 674.05, 673.95, 668.95, 668.95, 666.45, 664.65, 664.35, 663.75, 662.75, 659.95, 657.25, 655.9, 654.4, 654, 652.95, 652.95, 648.7, 647.95, 646.8, 645.35, 645.05, 644.5, 641.25, 640.8, 635, 634.85, 633.65, 632.75, 631.45, 630.7, 630.6, 629.6, 628.5, 627.6, 627.2, 627.2, 625.6, 625.55, 622.75, 622.65, 622.4, 621.7, 621.65, 621.3, 619.45, 616.4, 615.85, 615.6, 611.05, 610.95, 610.4, 610.2, 609.95, 609.3, 608.1, 606.95, 605.45, 605.35, 605.25, 605, 604.75, 604.1, 603.7, 602.15, 601.4, 600.85, 600.2, 599.6, 598.1, 596.35, 596.1, 594.55, 590.8, 590.7, 589.75, 589.35, 588.45, 587.05, 585.7, 585.6, 585.35, 585.15, 584.65, 583.7, 582.1, 580.3, 579.2, 571.35, 571.3, 568.95, 568.95, 566.85, 563.85, 559.1, 557.25, 556.25, 555.7, 555.7, 555.2, 554.75, 554.35, 553.4, 552.2, 547.95, 545.95, 545.55, 544.9, 543.65, 543, 541.7, 540.85, 538.15, 536.65, 535.5, 532.45, 531, 526.9, 526.05, 525.9, 523.55, 521.85, 519.23, 519.05, 519.05, 518.3, 518.3, 516.6, 516.35, 515.9, 514.5, 510.6, 510.45, 508.8, 504.85, 504.5, 501.45, 500.9, 500, 498.45, 494.8, 490.45, 481.6, 481.19, 479.15, 475.45, 475.3, 472.2, 470.45, 468.2, 468.2, 466, 463.95, 463.8, 453.6, 453.4, 452.75, 445.05, 444.04, 443.05, 440.81, 440.8, 439.07, 435.59, 428.9, 427.2, 418.6, 418.6, 417.6, 416.25, 412.55, 410.3, 405.95, 404.87, 398.55, 398.55, 396.14, 391.88, 389.94, 379.94, 378.43, 376.5, 366.22, 359.11, 355.65, 350.52, 341.35, 340.55, 336.22, 333.15, 333.15, 330.2, 323.02, 323.02, 321.5, 308, 294.23, 285.17, 275.71, 272.2, 272.2, 263.07, 236.62, 203.19, 203.19, 188.37, 171.07, 168.75, 168.47, 163.53, 151.66, 21.05]\n",
    "\n",
    "# Perform K-S test\n",
    "ks_statistic, p_value = ks_2samp(naia_scores, diii_scores)\n",
    "\n",
    "print(f\"K-S Test Results:\")\n",
    "print(f\"Statistic (D): {ks_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"NAIA mean: {np.mean(naia_scores):.1f}\")\n",
    "print(f\"DIII mean: {np.mean(diii_scores):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Analysis: Time vs. FINA Points\n",
    "\n",
    "To empirically validate the observations from the charts, a statistical analysis was performed on the raw time and FINA point distributions for the 50 Freestyle, 100 Breaststroke, and 100 Backstroke events. The following tables summarize the findings.\n",
    "\n",
    "**Key Observations:**\n",
    "1.  **Skewness:** For every event, the raw `Time` data exhibits positive skewness (e.g., `2.19` for 50 Free), which is typical for performance data where elite performers cluster at the fast end and a long tail of slower performers extends to the right. Conversely, the `FINA` scores consistently show negative skewness (e.g., `-0.89` for 50 Free), confirming the visual observation that the FINA calculation reverses the natural distribution of the data.\n",
    "2.  **Normality:** The Shapiro-Wilk test for normality was conducted. For all events, the p-value for the raw `Time` data is exceptionally small (p < 0.0001), leading us to reject the null hypothesis and conclude that the **raw time data is not normally distributed**. While the FINA scores are also not perfectly normal, their skewness and kurtosis values are closer to zero, confirming that the calculation pushes the data towards a more centralized, but ultimately distorted, distribution.\n",
    "\n",
    "These statistics provide quantitative proof that the FINA points system fundamentally alters the inherent statistical properties of performance data, supporting the argument that it is a flawed metric for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric | 50 Free Time | 50 Free FINA | 100 Br Time | 100 Br FINA | 100 Back Time | 100 Bk FINA |\n",
    "|:---|---:|---:|---:|---:|---:|---:|\n",
    "| **Mean** | 22.64 | 472.20 | 61.02 | 534.80 | 53.11 | 543.79 |\n",
    "| **Median** | 22.45 | 484.29 | 60.19 | 557.23 | 52.98 | 547.81 |\n",
    "| **Std Dev** | 1.75 | 121.04 | 5.18 | 121.86 | 4.21 | 125.58 |\n",
    "| **Skewness** | 2.19 | -0.89 | 2.08 | -0.93 | 1.99 | -0.99 |\n",
    "| **Kurtosis** | 5.99 | 0.57 | 4.85 | 0.42 | 4.69 | 0.59 |\n",
    "| **Shapiro-Wilk p-value** | < 0.0001 | < 0.0001 | < 0.0001 | < 0.0001 | < 0.0001 | < 0.0001 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification Code\n",
    "\n",
    "You can run the following Python code to reproduce the statistical analysis above using the `All Valuable Data - test.csv.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro, skew, kurtosis\n",
    "\n",
    "def analyze_and_print(df, column_name):\n",
    "    try:\n",
    "        print(f'--- {column_name} ---')\n",
    "        data = pd.to_numeric(df[column_name], errors='coerce').dropna()\n",
    "        if data.empty:\n",
    "            print('  (No valid data found)')\n",
    "            return\n",
    "        desc_stats = data.describe()\n",
    "        skewness = skew(data)\n",
    "        kurt = kurtosis(data)\n",
    "        shap = shapiro(data)\n",
    "        print(f"  Mean: {desc_stats['mean']:.2f}")\n",
    "        print(f"  Median: {desc_stats['50%']:.2f}")\n",
    "        print(f"  Standard Deviation: {desc_stats['std']:.2f}")\n",
    "        print(f"  Skewness: {skewness:.2f}")\n",
    "        print(f"  Kurtosis: {kurt:.2f}")\n",
    "        print(f"  Shapiro-Wilk p-value: {shap.pvalue:.4f}")\n",
    "        if shap.pvalue < 0.05:\n",
    "            print('  (Conclusion: Data is not normally distributed)')\n",
    "        else:\n",
    "            print('  (Conclusion: Data is likely normally distributed)')\n",
    "    except Exception as e:\n",
    "        print(f'  (An error occurred during analysis: {e})')\n",
    "    finally:\n",
    "        print('\n')\n",
    "\n",
    "file_path = 'All Valuable Data - test.csv.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_analyze = ['50 Free Time', '50 Free FINA', '100 Br Time', '100 Br FINA', '100 Back Time', '100 Bk FINA']\n",
    "for col in columns_to_analyze:\n",
    "    analyze_and_print(df, col)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
